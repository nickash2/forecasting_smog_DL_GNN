{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting script...\n",
      "\n",
      "Running __init__.py for data pipeline...\n",
      "\n",
      "Running __init__.py for data pipeline...\n",
      "Pipeline initialized\n",
      "\n",
      "Modelling package initialized\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting script...\")\n",
    "\n",
    "from modelling import *\n",
    "from modelling import GRU\n",
    "\n",
    "from pipeline import normalise_linear\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR:  /home/nick/bachelor-project/forecasting_smog_DL_GNN/src\n",
      "MODEL_PATH:  /home/nick/bachelor-project/forecasting_smog_DL_GNN/src/results/models\n",
      "MINMAX_PATH:  /home/nick/bachelor-project/forecasting_smog_DL_GNN/data/data_combined/amsterdam/contaminant_minmax.csv\n"
     ]
    }
   ],
   "source": [
    "HABROK = bool(0)                  # set to True if using HABROK; it will print\n",
    "                                  # all stdout to a .txt file to log progress\n",
    "CITY_NAME = \"Amsterdam\"\n",
    "BASE_DIR = Path.cwd()\n",
    "MODEL_PATH = BASE_DIR / \"results\" / \"models\"\n",
    "MINMAX_PATH = BASE_DIR.parent / \"data\" / \"data_combined\" / CITY_NAME.lower() / \"contaminant_minmax.csv\"\n",
    "\n",
    "print(\"BASE_DIR: \", BASE_DIR)\n",
    "print(\"MODEL_PATH: \", MODEL_PATH)\n",
    "print(\"MINMAX_PATH: \", MINMAX_PATH)\n",
    "\n",
    "torch.manual_seed(34)             # set seed for reproducibility\n",
    "\n",
    "N_HOURS_U = 72                    # number of hours to use for input\n",
    "N_HOURS_Y = 24                    # number of hours to predict\n",
    "N_HOURS_STEP = 24                 # \"sampling rate\" in hours of the data; e.g. 24 \n",
    "                                  # means sample an I/O-pair every 24 hours\n",
    "                                  # the contaminants and meteorological vars\n",
    "CONTAMINANTS = ['NO2', 'O3'] # 'PM10', 'PM25']\n",
    "COMPONENTS = ['NO2', 'O3', 'PM10', 'PM25', 'SQ', 'WD', 'Wvh', 'dewP', 'p', 'temp']\n",
    "WEATHER_COMP = ['SQ', 'WD', 'Wvh', 'dewP', 'p', 'temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_gru = {\n",
    "    'n_hours_u' : N_HOURS_U,\n",
    "    'n_hours_y' : N_HOURS_Y,\n",
    "\n",
    "    'model_class' : GRU, # changed to GRU\n",
    "    'input_units' : 8, #train_dataset.__n_features_in__(),\n",
    "    'hidden_layers' : 6,\n",
    "    'hidden_units' : 128,\n",
    "    # 'branches' : 2,  # predicting only no2 and o3\n",
    "    'output_units' : 2, #train_dataset.__n_features_out__(),\n",
    "\n",
    "    'Optimizer' : torch.optim.Adam,\n",
    "    'lr_shared' : 1e-3,\n",
    "    'scheduler' : torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    'scheduler_kwargs' : {'mode' : 'min',\n",
    "                          'factor' : 0.1,\n",
    "                          'patience' : 3,\n",
    "                          'cooldown' : 8,\n",
    "                          'verbose' : True},\n",
    "    'w_decay' : 1e-5,\n",
    "    'loss_fn' : torch.nn.MSELoss(),\n",
    "\n",
    "    'epochs' : 5000,\n",
    "    'early_stopper' : EarlyStopper,\n",
    "    'patience' : 15,\n",
    "    'batch_sz' : 16,\n",
    "    'k_folds' : 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utrecht model and evaluating at Amsterdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Printing model:\n",
      "GRU(\n",
      "  (gru): GRU(8, 128, num_layers=6, batch_first=True)\n",
      "  (dense): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "with PrintManager('.', 'a', HABROK):\n",
    "    print(\"\\nPrinting model:\")\n",
    "    model_utrecht = GRU(hp_gru['n_hours_u'],\n",
    "                 hp_gru['n_hours_y'],\n",
    "                 hp_gru['input_units'],\n",
    "                 hp_gru['hidden_layers'],\n",
    "                 hp_gru['hidden_units'], \n",
    "                #  hp['branches'],\n",
    "                 hp_gru['output_units'])\n",
    "    print(model_utrecht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_utrecht.load_state_dict(torch.load(f\"{MODEL_PATH}/model_GRU_utrecht.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_then_normalize_with_utrecht(\n",
    "    df, rotterdam_minmax_path, utrecht_minmax_path, contaminants=[\"NO2\", \"O3\"]\n",
    "):\n",
    "    \"\"\"\n",
    "    Denormalizes Rotterdam data and then normalizes it with Utrecht parameters\n",
    "    \n",
    "    :param df: DataFrame with normalized Rotterdam data\n",
    "    :param rotterdam_minmax_path: Path to Rotterdam's min/max values\n",
    "    :param utrecht_minmax_path: Path to Utrecht's min/max values\n",
    "    :param contaminants: List of contaminants to process\n",
    "    :return: DataFrame normalized with Utrecht parameters\n",
    "    \"\"\"\n",
    "    # Get min/max values\n",
    "    rotterdam_params = retrieve_min_max(rotterdam_minmax_path, conts=contaminants)\n",
    "    utrecht_params = retrieve_min_max(utrecht_minmax_path, conts=contaminants)\n",
    "    \n",
    "    # Create a copy to avoid modifying original\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Process each contaminant\n",
    "    for cont in contaminants:\n",
    "        if cont in df_copy.columns:\n",
    "            # Step 1: Denormalize using Rotterdam parameters\n",
    "            r_min = rotterdam_params[f\"{cont}_min\"]\n",
    "            r_max = rotterdam_params[f\"{cont}_max\"]\n",
    "            denormalized = df_copy[cont] * (r_max - r_min) + r_min\n",
    "\n",
    "            # Step 2: Normalize using Utrecht parameters\n",
    "            u_min = utrecht_params[f\"{cont}_min\"]\n",
    "            u_max = utrecht_params[f\"{cont}_max\"]\n",
    "            df_copy[cont] = (denormalized - u_min) / (u_max - u_min)\n",
    "            print(\"Normalized with Utrecht parameters\")\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset_for_cross_city(city_name, calc_new_params=False):\n",
    "    \"\"\"\n",
    "    Normalizes a city's dataset using Utrecht's normalization parameters\n",
    "    \n",
    "    :param city_name: Name of the city whose data needs to be normalized\n",
    "    :return: Tuple of normalized input and output frames\n",
    "    \"\"\"\n",
    "    # Define paths\n",
    "    city_minmax = BASE_DIR.parent / \"data\" / \"data_combined\" / city_name.lower() / \"contaminant_minmax.csv\"\n",
    "    utrecht_minmax = Path(MINMAX_PATH)\n",
    "    \n",
    "    # Get all dataframes\n",
    "    train_input_frames = get_dataframes('train', 'u', city_name)\n",
    "    train_output_frames = get_dataframes('train', 'y', city_name)\n",
    "    val_input_frames = get_dataframes('val', 'u', city_name)\n",
    "    val_output_frames = get_dataframes('val', 'y', city_name)\n",
    "    test_input_frames = get_dataframes('test', 'u', city_name)\n",
    "    test_output_frames = get_dataframes('test', 'y', city_name)\n",
    "\n",
    "    # Combine frames into list structure\n",
    "    input_frames = [train_input_frames, val_input_frames, test_input_frames]\n",
    "    output_frames = [train_output_frames, val_output_frames, test_output_frames]\n",
    "\n",
    "    # Transform each nested frame to Utrecht's normalization space\n",
    "    re_normalized_input_frames = []\n",
    "    for frame_list in input_frames:\n",
    "        normalized_list = []\n",
    "        for frame in frame_list:\n",
    "            normalized_frame = denormalize_then_normalize_with_target(frame, city_minmax, utrecht_minmax, no_target=calc_new_params)\n",
    "            normalized_list.append(normalized_frame)\n",
    "        re_normalized_input_frames.append(normalized_list)\n",
    "\n",
    "    re_normalized_output_frames = []\n",
    "    for frame_list in output_frames:\n",
    "        normalized_list = []\n",
    "        for frame in frame_list:\n",
    "            normalized_frame = denormalize_then_normalize_with_target(frame, city_minmax, utrecht_minmax, no_target=calc_new_params)\n",
    "            normalized_list.append(normalized_frame)\n",
    "        re_normalized_output_frames.append(normalized_list)\n",
    "    \n",
    "    return re_normalized_input_frames, re_normalized_output_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_normalized_input_frames, re_normalized_output_frames = normalize_dataset_for_cross_city('Amsterdam')\n",
    "train_input_frames_ams, val_input_frames_ams, test_input_frames_ams = re_normalized_input_frames\n",
    "train_output_frames_ams, val_output_frames_ams, test_output_frames_ams = re_normalized_output_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ams_dataset = TimeSeriesDataset(\n",
    "    train_input_frames_ams,\n",
    "    train_output_frames_ams,\n",
    "    5,\n",
    "    N_HOURS_U,\n",
    "    N_HOURS_Y,\n",
    "    N_HOURS_STEP,\n",
    ")\n",
    "\n",
    "\n",
    "val_ams_dataset = TimeSeriesDataset(\n",
    "    val_input_frames_ams,\n",
    "    val_output_frames_ams,\n",
    "    3,\n",
    "    N_HOURS_U,\n",
    "    N_HOURS_Y,\n",
    "    N_HOURS_STEP,\n",
    ")\n",
    "\n",
    "test_ams_dataset = TimeSeriesDataset(\n",
    "    test_input_frames_ams,\n",
    "    test_output_frames_ams,\n",
    "    3,\n",
    "    N_HOURS_U,\n",
    "    N_HOURS_Y,\n",
    "    N_HOURS_STEP,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007195948333180738"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset = ConcatDataset([train_ams_dataset, val_ams_dataset, test_ams_dataset])\n",
    "test_loader = DataLoader(full_dataset, batch_size=16, shuffle=False)\n",
    "loss_fn = nn.MSELoss()  # Instantiate the loss function\n",
    "test_error = test(model_utrecht, loss_fn, test_loader)\n",
    "test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE Test set:\n",
      "NO2: 15.922462916585815\n",
      "O3 : 9.596654612042402\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRMSE Test set:\")\n",
    "print_dict_vertically_root(\n",
    "    test_separately(model_utrecht, nn.MSELoss(), test_loader, True, MINMAX_PATH, components=[\"NO2\", \"O3\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utrecht model and evaluating Rotterdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_normalized_input_frames, re_normalized_output_frames = normalize_dataset_for_cross_city('Rotterdam')\n",
    "train_input_frames_rot, val_input_frames_rot, test_input_frames_rot = re_normalized_input_frames\n",
    "train_output_frames_rot, val_output_frames_rot, test_output_frames_rot = re_normalized_output_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rot_dataset = TimeSeriesDataset(\n",
    "    train_input_frames_rot,\n",
    "    train_output_frames_rot,\n",
    "    5,\n",
    "    N_HOURS_U,\n",
    "    N_HOURS_Y,\n",
    "    N_HOURS_STEP,\n",
    ")\n",
    "\n",
    "\n",
    "val_rot_dataset = TimeSeriesDataset(\n",
    "    val_input_frames_rot,\n",
    "    val_output_frames_rot,\n",
    "    3,\n",
    "    N_HOURS_U,\n",
    "    N_HOURS_Y,\n",
    "    N_HOURS_STEP,\n",
    ")\n",
    "\n",
    "test_rot_dataset = TimeSeriesDataset(\n",
    "    test_input_frames_rot,\n",
    "    test_output_frames_rot,\n",
    "    3,\n",
    "    N_HOURS_U,\n",
    "    N_HOURS_Y,\n",
    "    N_HOURS_STEP,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007277254849883183"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_rot_dataset = ConcatDataset([train_rot_dataset, val_rot_dataset, test_rot_dataset])\n",
    "\n",
    "test_loader = DataLoader(full_rot_dataset, batch_size=16, shuffle=False)\n",
    "loss_fn = nn.MSELoss()  # Instantiate the loss function\n",
    "test_error = test(model_utrecht, loss_fn, test_loader)\n",
    "test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE Test set:\n",
      "NO2: 15.282571441015362\n",
      "O3 : 11.516198351493946\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRMSE Test set:\")\n",
    "print_dict_vertically_root(\n",
    "    test_separately(model_utrecht, nn.MSELoss(), test_loader, True, MINMAX_PATH, components=[\"NO2\", \"O3\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_frames = get_dataframes('test', 'u', 'Utrecht')\n",
    "test_output_frames = get_dataframes('test', 'y', 'Utrecht')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_utrecht_dataset = TimeSeriesDataset(\n",
    "    test_input_frames,\n",
    "    test_output_frames,\n",
    "    3,\n",
    "    N_HOURS_U,\n",
    "    N_HOURS_Y,\n",
    "    N_HOURS_STEP,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "utrecht_test_loader = DataLoader(test_utrecht_dataset, batch_size=16, shuffle=False)\n",
    "one_model_dataset = ConcatDataset([full_dataset, full_rot_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
