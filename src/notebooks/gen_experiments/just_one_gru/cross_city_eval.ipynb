{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting script...\n",
      "/home/nick/bachelor-project/forecasting_smog_DL_GNN/src\n",
      "\n",
      "Running __init__.py for data pipeline...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelling package initialized\n",
      "\n",
      "\n",
      "Running __init__.py for data pipeline...\n",
      "Pipeline initialized\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting script...\")\n",
    "import os\n",
    "os.chdir(\"../../../\")\n",
    "print(os.getcwd())\n",
    "from modelling import *\n",
    "from modelling import GRU\n",
    "\n",
    "from pipeline import normalise_linear\n",
    "\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import ConcatDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR:  /home/nick/bachelor-project/forecasting_smog_DL_GNN/src\n",
      "MODEL_PATH:  /home/nick/bachelor-project/forecasting_smog_DL_GNN/src/results/models\n",
      "MINMAX_PATH:  /home/nick/bachelor-project/forecasting_smog_DL_GNN/data/data_combined/amsterdam/contaminant_minmax.csv\n"
     ]
    }
   ],
   "source": [
    "HABROK = bool(0)                  # set to True if using HABROK; it will print\n",
    "                                  # all stdout to a .txt file to log progress\n",
    "CITY_NAME = \"Amsterdam\"\n",
    "BASE_DIR = Path.cwd()\n",
    "MODEL_PATH = BASE_DIR / \"results\" / \"models\"\n",
    "MINMAX_PATH = BASE_DIR.parent / \"data\" / \"data_combined\" / CITY_NAME.lower() / \"contaminant_minmax.csv\"\n",
    "\n",
    "print(\"BASE_DIR: \", BASE_DIR)\n",
    "print(\"MODEL_PATH: \", MODEL_PATH)\n",
    "print(\"MINMAX_PATH: \", MINMAX_PATH)\n",
    "\n",
    "torch.manual_seed(34)             # set seed for reproducibility\n",
    "\n",
    "N_HOURS_U = 72                    # number of hours to use for input\n",
    "N_HOURS_Y = 24                    # number of hours to predict\n",
    "N_HOURS_STEP = 24                 # \"sampling rate\" in hours of the data; e.g. 24 \n",
    "                                  # means sample an I/O-pair every 24 hours\n",
    "                                  # the contaminants and meteorological vars\n",
    "CONTAMINANTS = ['NO2', 'O3'] # 'PM10', 'PM25']\n",
    "COMPONENTS = ['NO2', 'O3', 'PM10', 'PM25', 'SQ', 'WD', 'Wvh', 'dewP', 'p', 'temp']\n",
    "WEATHER_COMP = ['SQ', 'WD', 'Wvh', 'dewP', 'p', 'temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_gru = {\n",
    "    'n_hours_u' : N_HOURS_U,\n",
    "    'n_hours_y' : N_HOURS_Y,\n",
    "\n",
    "    'model_class' : GRU, # changed to GRU\n",
    "    'input_units' : 8, #train_dataset.__n_features_in__(),\n",
    "    'hidden_layers' : 6,\n",
    "    'hidden_units' : 128,\n",
    "    # 'branches' : 2,  # predicting only no2 and o3\n",
    "    'output_units' : 2, #train_dataset.__n_features_out__(),\n",
    "\n",
    "    'Optimizer' : torch.optim.Adam,\n",
    "    'lr_shared' : 1e-3,\n",
    "    'scheduler' : torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    'scheduler_kwargs' : {'mode' : 'min',\n",
    "                          'factor' : 0.1,\n",
    "                          'patience' : 3,\n",
    "                          'cooldown' : 8,\n",
    "                          'verbose' : True},\n",
    "    'w_decay' : 1e-5,\n",
    "    'loss_fn' : torch.nn.MSELoss(),\n",
    "\n",
    "    'epochs' : 5000,\n",
    "    'early_stopper' : EarlyStopper,\n",
    "    'patience' : 15,\n",
    "    'batch_sz' : 16,\n",
    "    'k_folds' : 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utrecht model and evaluating at Amsterdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Printing model:\n",
      "GRU(\n",
      "  (gru): GRU(8, 128, num_layers=6, batch_first=True)\n",
      "  (dense): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "with PrintManager('.', 'a', HABROK):\n",
    "    print(\"\\nPrinting model:\")\n",
    "    model_utrecht = GRU(hp_gru['n_hours_u'],\n",
    "                 hp_gru['n_hours_y'],\n",
    "                 hp_gru['input_units'],\n",
    "                 hp_gru['hidden_layers'],\n",
    "                 hp_gru['hidden_units'], \n",
    "                #  hp['branches'],\n",
    "                 hp_gru['output_units'])\n",
    "    print(model_utrecht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_utrecht.load_state_dict(torch.load(f\"{MODEL_PATH}/model_GRU_utrecht.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_then_normalize_with_utrecht(\n",
    "    df, rotterdam_minmax_path, utrecht_minmax_path, contaminants=[\"NO2\", \"O3\"]\n",
    "):\n",
    "    \"\"\"\n",
    "    Denormalizes Rotterdam data and then normalizes it with Utrecht parameters\n",
    "    \n",
    "    :param df: DataFrame with normalized Rotterdam data\n",
    "    :param rotterdam_minmax_path: Path to Rotterdam's min/max values\n",
    "    :param utrecht_minmax_path: Path to Utrecht's min/max values\n",
    "    :param contaminants: List of contaminants to process\n",
    "    :return: DataFrame normalized with Utrecht parameters\n",
    "    \"\"\"\n",
    "    # Get min/max values\n",
    "    rotterdam_params = retrieve_min_max(rotterdam_minmax_path, conts=contaminants)\n",
    "    utrecht_params = retrieve_min_max(utrecht_minmax_path, conts=contaminants)\n",
    "    \n",
    "    # Create a copy to avoid modifying original\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Process each contaminant\n",
    "    for cont in contaminants:\n",
    "        if cont in df_copy.columns:\n",
    "            # Step 1: Denormalize using Rotterdam parameters\n",
    "            r_min = rotterdam_params[f\"{cont}_min\"]\n",
    "            r_max = rotterdam_params[f\"{cont}_max\"]\n",
    "            denormalized = df_copy[cont] * (r_max - r_min) + r_min\n",
    "\n",
    "            # Step 2: Normalize using Utrecht parameters\n",
    "            u_min = utrecht_params[f\"{cont}_min\"]\n",
    "            u_max = utrecht_params[f\"{cont}_max\"]\n",
    "            df_copy[cont] = (denormalized - u_min) / (u_max - u_min)\n",
    "            print(\"Normalized with Utrecht parameters\")\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset_for_cross_city(city_name):\n",
    "    \"\"\"\n",
    "    Normalizes a city's dataset using Utrecht's normalization parameters\n",
    "    \n",
    "    :param city_name: Name of the city whose data needs to be normalized\n",
    "    :return: Tuple of normalized input and output frames\n",
    "    \"\"\"\n",
    "    # Define paths\n",
    "    city_minmax = BASE_DIR.parent / \"data\" / \"data_combined\" / city_name.lower() / \"contaminant_minmax.csv\"\n",
    "    utrecht_minmax = Path(MINMAX_PATH)\n",
    "    \n",
    "    # Get all dataframes\n",
    "    train_input_frames = get_dataframes('train', 'u', city_name)\n",
    "    train_output_frames = get_dataframes('train', 'y', city_name)\n",
    "    val_input_frames = get_dataframes('val', 'u', city_name)\n",
    "    val_output_frames = get_dataframes('val', 'y', city_name)\n",
    "    test_input_frames = get_dataframes('test', 'u', city_name)\n",
    "    test_output_frames = get_dataframes('test', 'y', city_name)\n",
    "\n",
    "    # Combine frames into list structure\n",
    "    input_frames = [train_input_frames, val_input_frames, test_input_frames]\n",
    "    output_frames = [train_output_frames, val_output_frames, test_output_frames]\n",
    "\n",
    "    # Transform each nested frame to Utrecht's normalization space\n",
    "    re_normalized_input_frames = []\n",
    "    for frame_list in input_frames:\n",
    "        normalized_list = []\n",
    "        for frame in frame_list:\n",
    "            normalized_frame = denormalize_then_normalize_with_utrecht(frame, city_minmax, utrecht_minmax)\n",
    "            normalized_list.append(normalized_frame)\n",
    "        re_normalized_input_frames.append(normalized_list)\n",
    "\n",
    "    re_normalized_output_frames = []\n",
    "    for frame_list in output_frames:\n",
    "        normalized_list = []\n",
    "        for frame in frame_list:\n",
    "            normalized_frame = denormalize_then_normalize_with_utrecht(frame, city_minmax, utrecht_minmax)\n",
    "            normalized_list.append(normalized_frame)\n",
    "        re_normalized_output_frames.append(normalized_list)\n",
    "    \n",
    "    return re_normalized_input_frames, re_normalized_output_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n"
     ]
    }
   ],
   "source": [
    "re_normalized_input_frames, re_normalized_output_frames = normalize_dataset_for_cross_city('Amsterdam')\n",
    "train_input_frames_ams, val_input_frames_ams, test_input_frames_ams = re_normalized_input_frames\n",
    "train_output_frames_ams, val_output_frames_ams, test_output_frames_ams = re_normalized_output_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ams_dataset = TimeSeriesDataset(\n",
    "    train_input_frames_ams,\n",
    "    train_output_frames_ams,\n",
    "    5,\n",
    "    N_HOURS_U,\n",
    "    N_HOURS_Y,\n",
    "    N_HOURS_STEP,\n",
    ")\n",
    "\n",
    "\n",
    "val_ams_dataset = TimeSeriesDataset(\n",
    "    val_input_frames_ams,\n",
    "    val_output_frames_ams,\n",
    "    3,\n",
    "    N_HOURS_U,\n",
    "    N_HOURS_Y,\n",
    "    N_HOURS_STEP,\n",
    ")\n",
    "\n",
    "test_ams_dataset = TimeSeriesDataset(\n",
    "    test_input_frames_ams,\n",
    "    test_output_frames_ams,\n",
    "    3,\n",
    "    N_HOURS_U,\n",
    "    N_HOURS_Y,\n",
    "    N_HOURS_STEP,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007195948333180738"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset = ConcatDataset([train_ams_dataset, val_ams_dataset, test_ams_dataset])\n",
    "test_loader = DataLoader(full_dataset, batch_size=16, shuffle=False)\n",
    "loss_fn = nn.MSELoss()  # Instantiate the loss function\n",
    "test_error = test(model_utrecht, loss_fn, test_loader)\n",
    "test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE Test set:\n",
      "NO2: 15.922462916585815\n",
      "O3 : 9.596654612042402\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRMSE Test set:\")\n",
    "print_dict_vertically_root(\n",
    "    test_separately(model_utrecht, nn.MSELoss(), test_loader, True, MINMAX_PATH, components=[\"NO2\", \"O3\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/rocm/lib/libamd_smi.so: cannot open shared object file: No such file or directory\n",
      "Unable to find amdsmi library try installing amd-smi-lib from your package manager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 16:25:41.180595: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-06 16:25:41.180652: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-06 16:25:41.180674: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-06 16:25:41.186877: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-06 16:25:42.037490: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-06 16:25:42,380] [zeus.device.gpu.nvidia](nvidia.py:47) pynvml is available and initialized.\n",
      "[2025-03-06 16:25:42,381] [zeus.device.cpu.rapl](rapl.py:137) RAPL is not supported on this CPU.\n",
      "[2025-03-06 16:25:42,381] [zeus.monitor.energy](energy.py:209) Monitoring GPU indices [0].\n",
      "[2025-03-06 16:25:42,382] [zeus.monitor.energy](energy.py:210) Monitoring CPU indices []\n",
      "[2025-03-06 16:25:42,383] [zeus.monitor.energy](energy.py:219) Writing measurement logs to logs/inference_test_20250306_162542/energy_20250306_162542.csv.\n",
      "[2025-03-06 16:25:42,384] [zeus.utils.framework](framework.py:25) PyTorch with CUDA support is available.\n",
      "Total Inference Energy: 37.10J\n",
      "Inference Time: 1.60s\n"
     ]
    }
   ],
   "source": [
    "from modelling.metrics.metricstracker import MetricsTracker\n",
    "\n",
    "# Initialize the tracker\n",
    "metrics_tracker = MetricsTracker(experiment_name=\"inference_test\", track_memory=True)\n",
    "\n",
    "# Function to test inference energy usage\n",
    "@metrics_tracker.track_window(\"inference\")\n",
    "def run_inference(model, data_loader):\n",
    "    test(model_utrecht, loss_fn, test_loader)\n",
    "\n",
    "# Run inference and track energy usage\n",
    "result, measurements = run_inference(model_utrecht, test_loader)\n",
    "\n",
    "# Display energy usage\n",
    "if \"energy\" in measurements:\n",
    "    print(f\"Total Inference Energy: {measurements['energy'].total_energy:.2f}J\")\n",
    "    print(f\"Inference Time: {measurements['energy'].time:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': [],\n",
       " 'val_loss': [],\n",
       " 'energy': {'epoch': [],\n",
       "  'step': [],\n",
       "  'inference': [{'step': 0,\n",
       "    'epoch': -1,\n",
       "    'energy': 37.09600000001956,\n",
       "    'time': 1.6024060249328613}]},\n",
       " 'memory': {'allocated': [0.0],\n",
       "  'reserved': [4.0],\n",
       "  'max_allocated': [2.09326171875]}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_tracker.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utrecht model and evaluating Rotterdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n",
      "Normalized with Utrecht parameters\n"
     ]
    }
   ],
   "source": [
    "re_normalized_input_frames, re_normalized_output_frames = normalize_dataset_for_cross_city('Rotterdam')\n",
    "train_input_frames_rot, val_input_frames_rot, test_input_frames_rot = re_normalized_input_frames\n",
    "train_output_frames_rot, val_output_frames_rot, test_output_frames_rot = re_normalized_output_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rot_dataset = TimeSeriesDataset(\n",
    "    train_input_frames_rot,\n",
    "    train_output_frames_rot,\n",
    "    5,\n",
    "    N_HOURS_U,\n",
    "    N_HOURS_Y,\n",
    "    N_HOURS_STEP,\n",
    ")\n",
    "\n",
    "\n",
    "val_rot_dataset = TimeSeriesDataset(\n",
    "    val_input_frames_rot,\n",
    "    val_output_frames_rot,\n",
    "    3,\n",
    "    N_HOURS_U,\n",
    "    N_HOURS_Y,\n",
    "    N_HOURS_STEP,\n",
    ")\n",
    "\n",
    "test_rot_dataset = TimeSeriesDataset(\n",
    "    test_input_frames_rot,\n",
    "    test_output_frames_rot,\n",
    "    3,\n",
    "    N_HOURS_U,\n",
    "    N_HOURS_Y,\n",
    "    N_HOURS_STEP,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007277254849883183"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_rot_dataset = ConcatDataset([train_rot_dataset, val_rot_dataset, test_rot_dataset])\n",
    "\n",
    "test_loader = DataLoader(full_rot_dataset, batch_size=16, shuffle=False)\n",
    "loss_fn = nn.MSELoss()  # Instantiate the loss function\n",
    "test_error = test(model_utrecht, loss_fn, test_loader)\n",
    "test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE Test set:\n",
      "NO2: 15.282571441015362\n",
      "O3 : 11.516198351493946\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRMSE Test set:\")\n",
    "print_dict_vertically_root(\n",
    "    test_separately(model_utrecht, nn.MSELoss(), test_loader, True, MINMAX_PATH, components=[\"NO2\", \"O3\"])\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
